{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification MLP vs. Logistic Regression\n",
    "\n",
    "In this notebook, I will compare the performance of shallow MLPs to that of a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# import from utils (a folder in the parent directory)\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from utils import MLP_generator\n",
    "\n",
    "# reset the path\n",
    "sys.path.append(\"Projects/Deep_Learning_MLPs\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581012, 55)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/covtype.data', header=None)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['elevation', 'aspect', 'slope', 'hor_dist_to_hydro', 'vert_dist_to_hydro', 'hor_dist_to_roadways', 'hillshade_9am', 'hillshade_noon', 'hillshade_3pm', 'hor_dist_to_fire_points', 'wilderness_area_1', 'wilderness_area_2', 'wilderness_area_3', 'wilderness_area_4']\n",
    "\n",
    "soil_columns = ['soil_type_' + str(i) for i in range(1, 41)]\n",
    "\n",
    "columns = columns + soil_columns + ['cover_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation</th>\n",
       "      <th>aspect</th>\n",
       "      <th>slope</th>\n",
       "      <th>hor_dist_to_hydro</th>\n",
       "      <th>vert_dist_to_hydro</th>\n",
       "      <th>hor_dist_to_roadways</th>\n",
       "      <th>hillshade_9am</th>\n",
       "      <th>hillshade_noon</th>\n",
       "      <th>hillshade_3pm</th>\n",
       "      <th>hor_dist_to_fire_points</th>\n",
       "      <th>...</th>\n",
       "      <th>soil_type_32</th>\n",
       "      <th>soil_type_33</th>\n",
       "      <th>soil_type_34</th>\n",
       "      <th>soil_type_35</th>\n",
       "      <th>soil_type_36</th>\n",
       "      <th>soil_type_37</th>\n",
       "      <th>soil_type_38</th>\n",
       "      <th>soil_type_39</th>\n",
       "      <th>soil_type_40</th>\n",
       "      <th>cover_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   elevation  aspect  slope  hor_dist_to_hydro  vert_dist_to_hydro  \\\n",
       "0       2596      51      3                258                   0   \n",
       "1       2590      56      2                212                  -6   \n",
       "2       2804     139      9                268                  65   \n",
       "3       2785     155     18                242                 118   \n",
       "4       2595      45      2                153                  -1   \n",
       "\n",
       "   hor_dist_to_roadways  hillshade_9am  hillshade_noon  hillshade_3pm  \\\n",
       "0                   510            221             232            148   \n",
       "1                   390            220             235            151   \n",
       "2                  3180            234             238            135   \n",
       "3                  3090            238             238            122   \n",
       "4                   391            220             234            150   \n",
       "\n",
       "   hor_dist_to_fire_points  ...  soil_type_32  soil_type_33  soil_type_34  \\\n",
       "0                     6279  ...             0             0             0   \n",
       "1                     6225  ...             0             0             0   \n",
       "2                     6121  ...             0             0             0   \n",
       "3                     6211  ...             0             0             0   \n",
       "4                     6172  ...             0             0             0   \n",
       "\n",
       "   soil_type_35  soil_type_36  soil_type_37  soil_type_38  soil_type_39  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   soil_type_40  cover_type  \n",
       "0             0           5  \n",
       "1             0           5  \n",
       "2             0           2  \n",
       "3             0           2  \n",
       "4             0           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = columns\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('cover_type', axis=1)\n",
    "y = data['cover_type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_columns = [\n",
    "    \"elevation\",\n",
    "    \"aspect\",\n",
    "    \"slope\",\n",
    "    \"hor_dist_to_hydro\",\n",
    "    \"vert_dist_to_hydro\",\n",
    "    \"hor_dist_to_roadways\",\n",
    "    \"hor_dist_to_fire_points\",\n",
    "]\n",
    "\n",
    "normalized_columns = [\"hillshade_9am\", \"hillshade_noon\", \"hillshade_3pm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "normalizer = MinMaxScaler(feature_range=(0, 255))\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    remainder=\"passthrough\",  # passthough features not listed\n",
    "    transformers=[\n",
    "        (\"std\", standard_scaler, standardized_columns),\n",
    "        (\"norm\", normalizer, normalized_columns),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(\n",
    "    multi_class=\"multinomial\", solver=\"sag\", penalty=None, random_state=0, max_iter=1500\n",
    ")\n",
    "\n",
    "logreg_pipe = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"logreg\", logreg_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;std&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;elevation&#x27;, &#x27;aspect&#x27;,\n",
       "                                                   &#x27;slope&#x27;, &#x27;hor_dist_to_hydro&#x27;,\n",
       "                                                   &#x27;vert_dist_to_hydro&#x27;,\n",
       "                                                   &#x27;hor_dist_to_roadways&#x27;,\n",
       "                                                   &#x27;hor_dist_to_fire_points&#x27;]),\n",
       "                                                 (&#x27;norm&#x27;,\n",
       "                                                  MinMaxScaler(feature_range=(0,\n",
       "                                                                              255)),\n",
       "                                                  [&#x27;hillshade_9am&#x27;,\n",
       "                                                   &#x27;hillshade_noon&#x27;,\n",
       "                                                   &#x27;hillshade_3pm&#x27;])])),\n",
       "                (&#x27;logreg&#x27;,\n",
       "                 LogisticRegression(max_iter=1500, multi_class=&#x27;multinomial&#x27;,\n",
       "                                    penalty=None, random_state=0,\n",
       "                                    solver=&#x27;sag&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;std&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;elevation&#x27;, &#x27;aspect&#x27;,\n",
       "                                                   &#x27;slope&#x27;, &#x27;hor_dist_to_hydro&#x27;,\n",
       "                                                   &#x27;vert_dist_to_hydro&#x27;,\n",
       "                                                   &#x27;hor_dist_to_roadways&#x27;,\n",
       "                                                   &#x27;hor_dist_to_fire_points&#x27;]),\n",
       "                                                 (&#x27;norm&#x27;,\n",
       "                                                  MinMaxScaler(feature_range=(0,\n",
       "                                                                              255)),\n",
       "                                                  [&#x27;hillshade_9am&#x27;,\n",
       "                                                   &#x27;hillshade_noon&#x27;,\n",
       "                                                   &#x27;hillshade_3pm&#x27;])])),\n",
       "                (&#x27;logreg&#x27;,\n",
       "                 LogisticRegression(max_iter=1500, multi_class=&#x27;multinomial&#x27;,\n",
       "                                    penalty=None, random_state=0,\n",
       "                                    solver=&#x27;sag&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;std&#x27;, StandardScaler(),\n",
       "                                 [&#x27;elevation&#x27;, &#x27;aspect&#x27;, &#x27;slope&#x27;,\n",
       "                                  &#x27;hor_dist_to_hydro&#x27;, &#x27;vert_dist_to_hydro&#x27;,\n",
       "                                  &#x27;hor_dist_to_roadways&#x27;,\n",
       "                                  &#x27;hor_dist_to_fire_points&#x27;]),\n",
       "                                (&#x27;norm&#x27;, MinMaxScaler(feature_range=(0, 255)),\n",
       "                                 [&#x27;hillshade_9am&#x27;, &#x27;hillshade_noon&#x27;,\n",
       "                                  &#x27;hillshade_3pm&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">std</label><div class=\"sk-toggleable__content\"><pre>[&#x27;elevation&#x27;, &#x27;aspect&#x27;, &#x27;slope&#x27;, &#x27;hor_dist_to_hydro&#x27;, &#x27;vert_dist_to_hydro&#x27;, &#x27;hor_dist_to_roadways&#x27;, &#x27;hor_dist_to_fire_points&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">norm</label><div class=\"sk-toggleable__content\"><pre>[&#x27;hillshade_9am&#x27;, &#x27;hillshade_noon&#x27;, &#x27;hillshade_3pm&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler(feature_range=(0, 255))</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;wilderness_area_1&#x27;, &#x27;wilderness_area_2&#x27;, &#x27;wilderness_area_3&#x27;, &#x27;wilderness_area_4&#x27;, &#x27;soil_type_1&#x27;, &#x27;soil_type_2&#x27;, &#x27;soil_type_3&#x27;, &#x27;soil_type_4&#x27;, &#x27;soil_type_5&#x27;, &#x27;soil_type_6&#x27;, &#x27;soil_type_7&#x27;, &#x27;soil_type_8&#x27;, &#x27;soil_type_9&#x27;, &#x27;soil_type_10&#x27;, &#x27;soil_type_11&#x27;, &#x27;soil_type_12&#x27;, &#x27;soil_type_13&#x27;, &#x27;soil_type_14&#x27;, &#x27;soil_type_15&#x27;, &#x27;soil_type_16&#x27;, &#x27;soil_type_17&#x27;, &#x27;soil_type_18&#x27;, &#x27;soil_type_19&#x27;, &#x27;soil_type_20&#x27;, &#x27;soil_type_21&#x27;, &#x27;soil_type_22&#x27;, &#x27;soil_type_23&#x27;, &#x27;soil_type_24&#x27;, &#x27;soil_type_25&#x27;, &#x27;soil_type_26&#x27;, &#x27;soil_type_27&#x27;, &#x27;soil_type_28&#x27;, &#x27;soil_type_29&#x27;, &#x27;soil_type_30&#x27;, &#x27;soil_type_31&#x27;, &#x27;soil_type_32&#x27;, &#x27;soil_type_33&#x27;, &#x27;soil_type_34&#x27;, &#x27;soil_type_35&#x27;, &#x27;soil_type_36&#x27;, &#x27;soil_type_37&#x27;, &#x27;soil_type_38&#x27;, &#x27;soil_type_39&#x27;, &#x27;soil_type_40&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1500, multi_class=&#x27;multinomial&#x27;, penalty=None,\n",
       "                   random_state=0, solver=&#x27;sag&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('std', StandardScaler(),\n",
       "                                                  ['elevation', 'aspect',\n",
       "                                                   'slope', 'hor_dist_to_hydro',\n",
       "                                                   'vert_dist_to_hydro',\n",
       "                                                   'hor_dist_to_roadways',\n",
       "                                                   'hor_dist_to_fire_points']),\n",
       "                                                 ('norm',\n",
       "                                                  MinMaxScaler(feature_range=(0,\n",
       "                                                                              255)),\n",
       "                                                  ['hillshade_9am',\n",
       "                                                   'hillshade_noon',\n",
       "                                                   'hillshade_3pm'])])),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(max_iter=1500, multi_class='multinomial',\n",
       "                                    penalty=None, random_state=0,\n",
       "                                    solver='sag'))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5807079796144847"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_logreg = logreg_pipe.predict(X_test)\n",
    "\n",
    "log_reg_accuracy = accuracy_score(y_test, y_pred_logreg)\n",
    "log_reg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LinearDiscriminantAnalysis()\n",
    "\n",
    "lda_pipe = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"lda\", lda_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;std&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;elevation&#x27;, &#x27;aspect&#x27;,\n",
       "                                                   &#x27;slope&#x27;, &#x27;hor_dist_to_hydro&#x27;,\n",
       "                                                   &#x27;vert_dist_to_hydro&#x27;,\n",
       "                                                   &#x27;hor_dist_to_roadways&#x27;,\n",
       "                                                   &#x27;hor_dist_to_fire_points&#x27;]),\n",
       "                                                 (&#x27;norm&#x27;,\n",
       "                                                  MinMaxScaler(feature_range=(0,\n",
       "                                                                              255)),\n",
       "                                                  [&#x27;hillshade_9am&#x27;,\n",
       "                                                   &#x27;hillshade_noon&#x27;,\n",
       "                                                   &#x27;hillshade_3pm&#x27;])])),\n",
       "                (&#x27;lda&#x27;, LinearDiscriminantAnalysis())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;std&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;elevation&#x27;, &#x27;aspect&#x27;,\n",
       "                                                   &#x27;slope&#x27;, &#x27;hor_dist_to_hydro&#x27;,\n",
       "                                                   &#x27;vert_dist_to_hydro&#x27;,\n",
       "                                                   &#x27;hor_dist_to_roadways&#x27;,\n",
       "                                                   &#x27;hor_dist_to_fire_points&#x27;]),\n",
       "                                                 (&#x27;norm&#x27;,\n",
       "                                                  MinMaxScaler(feature_range=(0,\n",
       "                                                                              255)),\n",
       "                                                  [&#x27;hillshade_9am&#x27;,\n",
       "                                                   &#x27;hillshade_noon&#x27;,\n",
       "                                                   &#x27;hillshade_3pm&#x27;])])),\n",
       "                (&#x27;lda&#x27;, LinearDiscriminantAnalysis())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;std&#x27;, StandardScaler(),\n",
       "                                 [&#x27;elevation&#x27;, &#x27;aspect&#x27;, &#x27;slope&#x27;,\n",
       "                                  &#x27;hor_dist_to_hydro&#x27;, &#x27;vert_dist_to_hydro&#x27;,\n",
       "                                  &#x27;hor_dist_to_roadways&#x27;,\n",
       "                                  &#x27;hor_dist_to_fire_points&#x27;]),\n",
       "                                (&#x27;norm&#x27;, MinMaxScaler(feature_range=(0, 255)),\n",
       "                                 [&#x27;hillshade_9am&#x27;, &#x27;hillshade_noon&#x27;,\n",
       "                                  &#x27;hillshade_3pm&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">std</label><div class=\"sk-toggleable__content\"><pre>[&#x27;elevation&#x27;, &#x27;aspect&#x27;, &#x27;slope&#x27;, &#x27;hor_dist_to_hydro&#x27;, &#x27;vert_dist_to_hydro&#x27;, &#x27;hor_dist_to_roadways&#x27;, &#x27;hor_dist_to_fire_points&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">norm</label><div class=\"sk-toggleable__content\"><pre>[&#x27;hillshade_9am&#x27;, &#x27;hillshade_noon&#x27;, &#x27;hillshade_3pm&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler(feature_range=(0, 255))</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;wilderness_area_1&#x27;, &#x27;wilderness_area_2&#x27;, &#x27;wilderness_area_3&#x27;, &#x27;wilderness_area_4&#x27;, &#x27;soil_type_1&#x27;, &#x27;soil_type_2&#x27;, &#x27;soil_type_3&#x27;, &#x27;soil_type_4&#x27;, &#x27;soil_type_5&#x27;, &#x27;soil_type_6&#x27;, &#x27;soil_type_7&#x27;, &#x27;soil_type_8&#x27;, &#x27;soil_type_9&#x27;, &#x27;soil_type_10&#x27;, &#x27;soil_type_11&#x27;, &#x27;soil_type_12&#x27;, &#x27;soil_type_13&#x27;, &#x27;soil_type_14&#x27;, &#x27;soil_type_15&#x27;, &#x27;soil_type_16&#x27;, &#x27;soil_type_17&#x27;, &#x27;soil_type_18&#x27;, &#x27;soil_type_19&#x27;, &#x27;soil_type_20&#x27;, &#x27;soil_type_21&#x27;, &#x27;soil_type_22&#x27;, &#x27;soil_type_23&#x27;, &#x27;soil_type_24&#x27;, &#x27;soil_type_25&#x27;, &#x27;soil_type_26&#x27;, &#x27;soil_type_27&#x27;, &#x27;soil_type_28&#x27;, &#x27;soil_type_29&#x27;, &#x27;soil_type_30&#x27;, &#x27;soil_type_31&#x27;, &#x27;soil_type_32&#x27;, &#x27;soil_type_33&#x27;, &#x27;soil_type_34&#x27;, &#x27;soil_type_35&#x27;, &#x27;soil_type_36&#x27;, &#x27;soil_type_37&#x27;, &#x27;soil_type_38&#x27;, &#x27;soil_type_39&#x27;, &#x27;soil_type_40&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('std', StandardScaler(),\n",
       "                                                  ['elevation', 'aspect',\n",
       "                                                   'slope', 'hor_dist_to_hydro',\n",
       "                                                   'vert_dist_to_hydro',\n",
       "                                                   'hor_dist_to_roadways',\n",
       "                                                   'hor_dist_to_fire_points']),\n",
       "                                                 ('norm',\n",
       "                                                  MinMaxScaler(feature_range=(0,\n",
       "                                                                              255)),\n",
       "                                                  ['hillshade_9am',\n",
       "                                                   'hillshade_noon',\n",
       "                                                   'hillshade_3pm'])])),\n",
       "                ('lda', LinearDiscriminantAnalysis())])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5838145794603917"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lda = lda_pipe.predict(X_test)\n",
    "\n",
    "lda_accuracy = accuracy_score(y_test, y_pred_lda)\n",
    "lda_accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_train)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.X_train.iloc[index]  # Assuming X_train is a pandas DataFrame\n",
    "        y = self.y_train.iloc[index]  # Assuming y_train is a pandas Series\n",
    "\n",
    "        # Adjust the target value by subtracting 1\n",
    "        y -= 1\n",
    "        \n",
    "        # Convert the variables to tensors\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.int64)\n",
    "\n",
    "\n",
    "        return x, y\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Loss after mini-batch   100: 1.916\n",
      "Train, Test accuracy after mini-batch 100: 0.36577820136873423, 0.36798533600681566\n",
      "Loss after mini-batch   200: 1.906\n",
      "Train, Test accuracy after mini-batch 200: 0.3653844912641537, 0.36718501243513507\n",
      "Loss after mini-batch   300: 1.907\n",
      "Train, Test accuracy after mini-batch 300: 0.36549421375231544, 0.36727106873316523\n",
      "Loss after mini-batch   400: 1.906\n",
      "Train, Test accuracy after mini-batch 400: 0.3656103905044868, 0.3673571250311954\n",
      "Loss after mini-batch   500: 1.897\n",
      "Train, Test accuracy after mini-batch 500: 0.3663354194948893, 0.36825211053070916\n",
      "Loss after mini-batch   600: 1.886\n",
      "Train, Test accuracy after mini-batch 600: 0.36534791710143305, 0.3673657306609984\n",
      "Loss after mini-batch   700: 1.887\n",
      "Train, Test accuracy after mini-batch 700: 0.36526616309064586, 0.3670903505073019\n",
      "Loss after mini-batch   800: 1.886\n",
      "Train, Test accuracy after mini-batch 800: 0.36527476877599185, 0.36711616739671094\n",
      "Loss after mini-batch   900: 1.887\n",
      "Train, Test accuracy after mini-batch 900: 0.36527476877599185, 0.36711616739671094\n",
      "Loss after mini-batch  1000: 1.885\n",
      "Train, Test accuracy after mini-batch 1000: 0.36527476877599185, 0.36711616739671094\n",
      "Loss after mini-batch  1100: 1.885\n",
      "Train, Test accuracy after mini-batch 1100: 0.3652855258826744, 0.36711616739671094\n",
      "Loss after mini-batch  1200: 1.887\n",
      "Train, Test accuracy after mini-batch 1200: 0.3652833744613379, 0.36711616739671094\n",
      "Loss after mini-batch  1300: 1.886\n",
      "Train, Test accuracy after mini-batch 1300: 0.36534361425876005, 0.36721082932454413\n",
      "Loss after mini-batch  1400: 1.886\n",
      "Train, Test accuracy after mini-batch 1400: 0.36535221994410605, 0.36721082932454413\n",
      "Loss after mini-batch  1500: 1.886\n",
      "Train, Test accuracy after mini-batch 1500: 0.36535221994410605, 0.36721082932454413\n",
      "Loss after mini-batch  1600: 1.885\n",
      "Train, Test accuracy after mini-batch 1600: 0.36535221994410605, 0.36721082932454413\n",
      "Loss after mini-batch  1700: 1.887\n",
      "Train, Test accuracy after mini-batch 1700: 0.36535221994410605, 0.36721082932454413\n",
      "Loss after mini-batch  1800: 1.887\n",
      "Train, Test accuracy after mini-batch 1800: 0.36536297705078863, 0.36721082932454413\n",
      "Loss after mini-batch  1900: 1.886\n",
      "Train, Test accuracy after mini-batch 1900: 0.3654533367469219, 0.36727967436296827\n",
      "Loss after mini-batch  2000: 1.885\n",
      "Train, Test accuracy after mini-batch 2000: 0.36592664944095316, 0.36772716711272513\n",
      "Loss after mini-batch  2100: 1.886\n",
      "Train, Test accuracy after mini-batch 2100: 0.36862238037559514, 0.37067889813516003\n",
      "Loss after mini-batch  2200: 1.886\n",
      "Train, Test accuracy after mini-batch 2200: 0.365330705730741, 0.36721082932454413\n",
      "Loss after mini-batch  2300: 1.885\n",
      "Train, Test accuracy after mini-batch 2300: 0.3659761321316928, 0.3678476459299674\n",
      "Loss after mini-batch  2400: 1.887\n",
      "Train, Test accuracy after mini-batch 2400: 0.36598904065971183, 0.3678648571895734\n",
      "Loss after mini-batch  2500: 1.885\n",
      "Train, Test accuracy after mini-batch 2500: 0.3661611543666323, 0.3680111528962247\n",
      "Loss after mini-batch  2600: 1.887\n",
      "Train, Test accuracy after mini-batch 2600: 0.36617191147331485, 0.36801975852602775\n",
      "Loss after mini-batch  2700: 1.885\n",
      "Train, Test accuracy after mini-batch 2700: 0.36662801279665413, 0.3684328287565726\n",
      "Loss after mini-batch  2800: 1.886\n",
      "Train, Test accuracy after mini-batch 2800: 0.3755714712925094, 0.3770126416701806\n",
      "Loss after mini-batch  2900: 1.888\n",
      "Train, Test accuracy after mini-batch 2900: 0.3738761512793427, 0.3755152620844556\n",
      "Loss after mini-batch  3000: 1.887\n",
      "Train, Test accuracy after mini-batch 3000: 0.36652474457250184, 0.36847585690558765\n",
      "Loss after mini-batch  3100: 1.887\n",
      "Train, Test accuracy after mini-batch 3100: 0.3665548644712129, 0.3685619132036178\n",
      "Loss after mini-batch  3200: 1.885\n",
      "Train, Test accuracy after mini-batch 3200: 0.36654410736453036, 0.36858773009302687\n",
      "Loss after mini-batch  3300: 1.885\n",
      "Train, Test accuracy after mini-batch 3300: 0.3776346843542186, 0.3792673166785711\n",
      "Loss after mini-batch  3400: 1.887\n",
      "Train, Test accuracy after mini-batch 3400: 0.3657588385767057, 0.36763250518489193\n",
      "Loss after mini-batch  3500: 1.887\n",
      "Train, Test accuracy after mini-batch 3500: 0.3668044293462476, 0.36883729335731436\n",
      "Loss after mini-batch  3600: 1.887\n",
      "Train, Test accuracy after mini-batch 3600: 0.36840293539927155, 0.37008510967875186\n",
      "Loss after mini-batch  3700: 1.885\n",
      "Train, Test accuracy after mini-batch 3700: 0.3660213119797594, 0.3679164909683915\n",
      "Loss after mini-batch  3800: 1.885\n",
      "Train, Test accuracy after mini-batch 3800: 0.36628808822548614, 0.36813163171346697\n",
      "Loss after mini-batch  3900: 1.885\n",
      "Train, Test accuracy after mini-batch 3900: 0.3646551594310781, 0.36667728027675706\n",
      "Loss after mini-batch  4000: 1.885\n",
      "Train, Test accuracy after mini-batch 4000: 0.3646702193804337, 0.3666858859065601\n",
      "Loss after mini-batch  4100: 1.886\n",
      "Train, Test accuracy after mini-batch 4100: 0.3647175506498368, 0.36675473094498423\n",
      "Loss after mini-batch  4200: 1.887\n",
      "Train, Test accuracy after mini-batch 4200: 0.3647175506498368, 0.36675473094498423\n",
      "Loss after mini-batch  4300: 1.886\n",
      "Train, Test accuracy after mini-batch 4300: 0.3647390648632019, 0.36678915346419627\n",
      "Loss after mini-batch  4400: 1.886\n",
      "Train, Test accuracy after mini-batch 4400: 0.3647390648632019, 0.36678915346419627\n",
      "Loss after mini-batch  4500: 1.886\n",
      "Train, Test accuracy after mini-batch 4500: 0.3653672798934616, 0.3673140968821803\n",
      "Loss after mini-batch  4600: 1.885\n",
      "Train, Test accuracy after mini-batch 4600: 0.3654683966962774, 0.36737433629080146\n",
      "Loss after mini-batch  4700: 1.886\n",
      "Train, Test accuracy after mini-batch 4700: 0.36548560806696945, 0.36737433629080146\n",
      "Loss after mini-batch  4800: 1.886\n",
      "Train, Test accuracy after mini-batch 4800: 0.365504970858998, 0.36738294192060444\n",
      "Loss after mini-batch  4900: 1.887\n",
      "Train, Test accuracy after mini-batch 4900: 0.365504970858998, 0.36738294192060444\n",
      "Loss after mini-batch  5000: 1.888\n",
      "Train, Test accuracy after mini-batch 5000: 0.365504970858998, 0.3674001531802105\n",
      "Loss after mini-batch  5100: 1.886\n",
      "Train, Test accuracy after mini-batch 5100: 0.36664737558868266, 0.3685447019440118\n",
      "Loss after mini-batch  5200: 1.886\n",
      "Train, Test accuracy after mini-batch 5200: 0.3666581326953652, 0.36858773009302687\n",
      "Loss after mini-batch  5300: 1.886\n",
      "Train, Test accuracy after mini-batch 5300: 0.3671271425467235, 0.3690610397321928\n",
      "Loss after mini-batch  5400: 1.889\n",
      "Train, Test accuracy after mini-batch 5400: 0.3718516638016906, 0.37438792458026043\n",
      "Loss after mini-batch  5500: 1.886\n",
      "Train, Test accuracy after mini-batch 5500: 0.3683362413378398, 0.37044654613047856\n",
      "Loss after mini-batch  5600: 1.887\n",
      "Train, Test accuracy after mini-batch 5600: 0.3673702531577487, 0.36942247618391955\n",
      "Loss after mini-batch  5700: 1.885\n",
      "Train, Test accuracy after mini-batch 5700: 0.36567278172324547, 0.36752923762725576\n",
      "Loss after mini-batch  5800: 1.886\n",
      "Train, Test accuracy after mini-batch 5800: 0.3670195714798982, 0.36888032150632943\n",
      "Loss after mini-batch  5900: 1.886\n",
      "Train, Test accuracy after mini-batch 5900: 0.3659761321316928, 0.36787346281937644\n",
      "Loss after mini-batch  6000: 1.886\n",
      "Train, Test accuracy after mini-batch 6000: 0.36603422050777845, 0.36796812474720964\n",
      "Loss after mini-batch  6100: 1.886\n",
      "Train, Test accuracy after mini-batch 6100: 0.36495205557551597, 0.3669526604304536\n",
      "Loss after mini-batch  6200: 1.886\n",
      "Train, Test accuracy after mini-batch 6200: 0.36495205557551597, 0.3669526604304536\n",
      "Loss after mini-batch  6300: 1.887\n",
      "Train, Test accuracy after mini-batch 6300: 0.36495205557551597, 0.3669526604304536\n",
      "Loss after mini-batch  6400: 1.884\n",
      "Train, Test accuracy after mini-batch 6400: 0.36495205557551597, 0.3669526604304536\n",
      "Loss after mini-batch  6500: 1.886\n",
      "Train, Test accuracy after mini-batch 6500: 0.36495205557551597, 0.3669526604304536\n",
      "Loss after mini-batch  6600: 1.888\n",
      "Train, Test accuracy after mini-batch 6600: 0.3649542069968525, 0.3669526604304536\n",
      "Loss after mini-batch  6700: 1.885\n",
      "Train, Test accuracy after mini-batch 6700: 0.36510265506907136, 0.3670903505073019\n",
      "Loss after mini-batch  6800: 1.885\n",
      "Train, Test accuracy after mini-batch 6800: 0.3670518427999458, 0.3690008003235717\n",
      "Loss after mini-batch  6900: 1.886\n",
      "Train, Test accuracy after mini-batch 6900: 0.36729495341097096, 0.369172912919632\n",
      "Loss after mini-batch  7000: 1.884\n",
      "Train, Test accuracy after mini-batch 7000: 0.3691215101256645, 0.3714275879280225\n",
      "Loss after mini-batch  7100: 1.886\n",
      "Train, Test accuracy after mini-batch 7100: 0.36930868378194054, 0.3715910948942798\n",
      "Loss after mini-batch  7200: 1.887\n",
      "Train, Test accuracy after mini-batch 7200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7300: 1.886\n",
      "Train, Test accuracy after mini-batch 7300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7400: 1.888\n",
      "Train, Test accuracy after mini-batch 7400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7500: 1.887\n",
      "Train, Test accuracy after mini-batch 7500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7600: 1.886\n",
      "Train, Test accuracy after mini-batch 7600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7700: 1.887\n",
      "Train, Test accuracy after mini-batch 7700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7800: 1.887\n",
      "Train, Test accuracy after mini-batch 7800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7900: 1.887\n",
      "Train, Test accuracy after mini-batch 7900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8000: 1.886\n",
      "Train, Test accuracy after mini-batch 8000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8100: 1.887\n",
      "Train, Test accuracy after mini-batch 8100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8200: 1.887\n",
      "Train, Test accuracy after mini-batch 8200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8300: 1.887\n",
      "Train, Test accuracy after mini-batch 8300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8400: 1.885\n",
      "Train, Test accuracy after mini-batch 8400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8500: 1.886\n",
      "Train, Test accuracy after mini-batch 8500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8600: 1.888\n",
      "Train, Test accuracy after mini-batch 8600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8700: 1.885\n",
      "Train, Test accuracy after mini-batch 8700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8800: 1.886\n",
      "Train, Test accuracy after mini-batch 8800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8900: 1.886\n",
      "Train, Test accuracy after mini-batch 8900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9000: 1.885\n",
      "Train, Test accuracy after mini-batch 9000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9100: 1.885\n",
      "Train, Test accuracy after mini-batch 9100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9200: 1.885\n",
      "Train, Test accuracy after mini-batch 9200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9300: 1.887\n",
      "Train, Test accuracy after mini-batch 9300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9400: 1.885\n",
      "Train, Test accuracy after mini-batch 9400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9500: 1.886\n",
      "Train, Test accuracy after mini-batch 9500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9600: 1.887\n",
      "Train, Test accuracy after mini-batch 9600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9700: 1.885\n",
      "Train, Test accuracy after mini-batch 9700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9800: 1.886\n",
      "Train, Test accuracy after mini-batch 9800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9900: 1.886\n",
      "Train, Test accuracy after mini-batch 9900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10000: 1.886\n",
      "Train, Test accuracy after mini-batch 10000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10100: 1.887\n",
      "Train, Test accuracy after mini-batch 10100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10200: 1.886\n",
      "Train, Test accuracy after mini-batch 10200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10300: 1.887\n",
      "Train, Test accuracy after mini-batch 10300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10400: 1.885\n",
      "Train, Test accuracy after mini-batch 10400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10500: 1.888\n",
      "Train, Test accuracy after mini-batch 10500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10600: 1.888\n",
      "Train, Test accuracy after mini-batch 10600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10700: 1.888\n",
      "Train, Test accuracy after mini-batch 10700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10800: 1.887\n",
      "Train, Test accuracy after mini-batch 10800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10900: 1.887\n",
      "Train, Test accuracy after mini-batch 10900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11000: 1.887\n",
      "Train, Test accuracy after mini-batch 11000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11100: 1.887\n",
      "Train, Test accuracy after mini-batch 11100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11200: 1.887\n",
      "Train, Test accuracy after mini-batch 11200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11300: 1.885\n",
      "Train, Test accuracy after mini-batch 11300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11400: 1.887\n",
      "Train, Test accuracy after mini-batch 11400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11500: 1.886\n",
      "Train, Test accuracy after mini-batch 11500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11600: 1.886\n",
      "Train, Test accuracy after mini-batch 11600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11700: 1.885\n",
      "Train, Test accuracy after mini-batch 11700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11800: 1.886\n",
      "Train, Test accuracy after mini-batch 11800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11900: 1.884\n",
      "Train, Test accuracy after mini-batch 11900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12000: 1.886\n",
      "Train, Test accuracy after mini-batch 12000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12100: 1.886\n",
      "Train, Test accuracy after mini-batch 12100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12200: 1.886\n",
      "Train, Test accuracy after mini-batch 12200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12300: 1.886\n",
      "Train, Test accuracy after mini-batch 12300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12400: 1.887\n",
      "Train, Test accuracy after mini-batch 12400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12500: 1.887\n",
      "Train, Test accuracy after mini-batch 12500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12600: 1.887\n",
      "Train, Test accuracy after mini-batch 12600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12700: 1.887\n",
      "Train, Test accuracy after mini-batch 12700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12800: 1.887\n",
      "Train, Test accuracy after mini-batch 12800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12900: 1.887\n",
      "Train, Test accuracy after mini-batch 12900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13000: 1.886\n",
      "Train, Test accuracy after mini-batch 13000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13100: 1.887\n",
      "Train, Test accuracy after mini-batch 13100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13200: 1.885\n",
      "Train, Test accuracy after mini-batch 13200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13300: 1.885\n",
      "Train, Test accuracy after mini-batch 13300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13400: 1.886\n",
      "Train, Test accuracy after mini-batch 13400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13500: 1.886\n",
      "Train, Test accuracy after mini-batch 13500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13600: 1.887\n",
      "Train, Test accuracy after mini-batch 13600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13700: 1.885\n",
      "Train, Test accuracy after mini-batch 13700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13800: 1.887\n",
      "Train, Test accuracy after mini-batch 13800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13900: 1.887\n",
      "Train, Test accuracy after mini-batch 13900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 14000: 1.886\n",
      "Train, Test accuracy after mini-batch 14000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 14100: 1.886\n",
      "Train, Test accuracy after mini-batch 14100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 14200: 1.886\n",
      "Train, Test accuracy after mini-batch 14200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 14300: 1.886\n",
      "Train, Test accuracy after mini-batch 14300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 14400: 1.887\n",
      "Train, Test accuracy after mini-batch 14400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 14500: 1.887\n",
      "Train, Test accuracy after mini-batch 14500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after epoch     1: 1.899\n",
      "Starting epoch 2\n",
      "Loss after mini-batch   100: 1.886\n",
      "Train, Test accuracy after mini-batch 100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   200: 1.886\n",
      "Train, Test accuracy after mini-batch 200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   300: 1.887\n",
      "Train, Test accuracy after mini-batch 300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   400: 1.886\n",
      "Train, Test accuracy after mini-batch 400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   500: 1.886\n",
      "Train, Test accuracy after mini-batch 500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   600: 1.887\n",
      "Train, Test accuracy after mini-batch 600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   700: 1.886\n",
      "Train, Test accuracy after mini-batch 700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   800: 1.885\n",
      "Train, Test accuracy after mini-batch 800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   900: 1.886\n",
      "Train, Test accuracy after mini-batch 900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1000: 1.887\n",
      "Train, Test accuracy after mini-batch 1000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1100: 1.886\n",
      "Train, Test accuracy after mini-batch 1100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1200: 1.887\n",
      "Train, Test accuracy after mini-batch 1200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1300: 1.886\n",
      "Train, Test accuracy after mini-batch 1300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1400: 1.886\n",
      "Train, Test accuracy after mini-batch 1400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1500: 1.885\n",
      "Train, Test accuracy after mini-batch 1500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1600: 1.887\n",
      "Train, Test accuracy after mini-batch 1600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1700: 1.887\n",
      "Train, Test accuracy after mini-batch 1700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1800: 1.886\n",
      "Train, Test accuracy after mini-batch 1800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1900: 1.886\n",
      "Train, Test accuracy after mini-batch 1900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2000: 1.886\n",
      "Train, Test accuracy after mini-batch 2000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2100: 1.887\n",
      "Train, Test accuracy after mini-batch 2100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2200: 1.885\n",
      "Train, Test accuracy after mini-batch 2200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2300: 1.886\n",
      "Train, Test accuracy after mini-batch 2300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2400: 1.886\n",
      "Train, Test accuracy after mini-batch 2400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2500: 1.887\n",
      "Train, Test accuracy after mini-batch 2500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2600: 1.885\n",
      "Train, Test accuracy after mini-batch 2600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2700: 1.887\n",
      "Train, Test accuracy after mini-batch 2700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2800: 1.887\n",
      "Train, Test accuracy after mini-batch 2800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2900: 1.885\n",
      "Train, Test accuracy after mini-batch 2900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3000: 1.887\n",
      "Train, Test accuracy after mini-batch 3000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3100: 1.885\n",
      "Train, Test accuracy after mini-batch 3100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3200: 1.885\n",
      "Train, Test accuracy after mini-batch 3200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3300: 1.887\n",
      "Train, Test accuracy after mini-batch 3300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3400: 1.887\n",
      "Train, Test accuracy after mini-batch 3400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3500: 1.887\n",
      "Train, Test accuracy after mini-batch 3500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3600: 1.886\n",
      "Train, Test accuracy after mini-batch 3600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3700: 1.885\n",
      "Train, Test accuracy after mini-batch 3700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3800: 1.886\n",
      "Train, Test accuracy after mini-batch 3800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3900: 1.886\n",
      "Train, Test accuracy after mini-batch 3900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4000: 1.885\n",
      "Train, Test accuracy after mini-batch 4000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4100: 1.887\n",
      "Train, Test accuracy after mini-batch 4100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4200: 1.887\n",
      "Train, Test accuracy after mini-batch 4200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4300: 1.888\n",
      "Train, Test accuracy after mini-batch 4300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4400: 1.888\n",
      "Train, Test accuracy after mini-batch 4400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4500: 1.886\n",
      "Train, Test accuracy after mini-batch 4500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4600: 1.887\n",
      "Train, Test accuracy after mini-batch 4600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4700: 1.886\n",
      "Train, Test accuracy after mini-batch 4700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4800: 1.888\n",
      "Train, Test accuracy after mini-batch 4800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4900: 1.885\n",
      "Train, Test accuracy after mini-batch 4900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5000: 1.886\n",
      "Train, Test accuracy after mini-batch 5000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5100: 1.886\n",
      "Train, Test accuracy after mini-batch 5100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5200: 1.887\n",
      "Train, Test accuracy after mini-batch 5200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5300: 1.886\n",
      "Train, Test accuracy after mini-batch 5300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5400: 1.887\n",
      "Train, Test accuracy after mini-batch 5400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5500: 1.885\n",
      "Train, Test accuracy after mini-batch 5500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5600: 1.886\n",
      "Train, Test accuracy after mini-batch 5600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5700: 1.886\n",
      "Train, Test accuracy after mini-batch 5700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5800: 1.887\n",
      "Train, Test accuracy after mini-batch 5800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5900: 1.886\n",
      "Train, Test accuracy after mini-batch 5900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6000: 1.887\n",
      "Train, Test accuracy after mini-batch 6000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6100: 1.886\n",
      "Train, Test accuracy after mini-batch 6100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6200: 1.887\n",
      "Train, Test accuracy after mini-batch 6200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6300: 1.887\n",
      "Train, Test accuracy after mini-batch 6300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6400: 1.887\n",
      "Train, Test accuracy after mini-batch 6400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6500: 1.886\n",
      "Train, Test accuracy after mini-batch 6500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6600: 1.885\n",
      "Train, Test accuracy after mini-batch 6600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6700: 1.885\n",
      "Train, Test accuracy after mini-batch 6700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6800: 1.886\n",
      "Train, Test accuracy after mini-batch 6800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6900: 1.888\n",
      "Train, Test accuracy after mini-batch 6900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7000: 1.886\n",
      "Train, Test accuracy after mini-batch 7000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7100: 1.886\n",
      "Train, Test accuracy after mini-batch 7100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7200: 1.885\n",
      "Train, Test accuracy after mini-batch 7200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7300: 1.885\n",
      "Train, Test accuracy after mini-batch 7300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7400: 1.887\n",
      "Train, Test accuracy after mini-batch 7400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7500: 1.887\n",
      "Train, Test accuracy after mini-batch 7500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7600: 1.887\n",
      "Train, Test accuracy after mini-batch 7600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7700: 1.885\n",
      "Train, Test accuracy after mini-batch 7700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7800: 1.887\n",
      "Train, Test accuracy after mini-batch 7800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7900: 1.884\n",
      "Train, Test accuracy after mini-batch 7900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8000: 1.886\n",
      "Train, Test accuracy after mini-batch 8000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8100: 1.886\n",
      "Train, Test accuracy after mini-batch 8100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8200: 1.886\n",
      "Train, Test accuracy after mini-batch 8200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8300: 1.885\n",
      "Train, Test accuracy after mini-batch 8300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8400: 1.887\n",
      "Train, Test accuracy after mini-batch 8400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8500: 1.886\n",
      "Train, Test accuracy after mini-batch 8500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8600: 1.886\n",
      "Train, Test accuracy after mini-batch 8600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8700: 1.887\n",
      "Train, Test accuracy after mini-batch 8700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8800: 1.887\n",
      "Train, Test accuracy after mini-batch 8800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8900: 1.887\n",
      "Train, Test accuracy after mini-batch 8900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9000: 1.888\n",
      "Train, Test accuracy after mini-batch 9000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9100: 1.889\n",
      "Train, Test accuracy after mini-batch 9100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9200: 1.886\n",
      "Train, Test accuracy after mini-batch 9200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9300: 1.886\n",
      "Train, Test accuracy after mini-batch 9300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9400: 1.886\n",
      "Train, Test accuracy after mini-batch 9400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9500: 1.885\n",
      "Train, Test accuracy after mini-batch 9500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9600: 1.885\n",
      "Train, Test accuracy after mini-batch 9600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9700: 1.888\n",
      "Train, Test accuracy after mini-batch 9700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9800: 1.887\n",
      "Train, Test accuracy after mini-batch 9800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9900: 1.886\n",
      "Train, Test accuracy after mini-batch 9900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10000: 1.886\n",
      "Train, Test accuracy after mini-batch 10000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10100: 1.887\n",
      "Train, Test accuracy after mini-batch 10100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10200: 1.886\n",
      "Train, Test accuracy after mini-batch 10200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10300: 1.885\n",
      "Train, Test accuracy after mini-batch 10300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10400: 1.888\n",
      "Train, Test accuracy after mini-batch 10400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10500: 1.885\n",
      "Train, Test accuracy after mini-batch 10500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10600: 1.886\n",
      "Train, Test accuracy after mini-batch 10600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10700: 1.886\n",
      "Train, Test accuracy after mini-batch 10700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10800: 1.887\n",
      "Train, Test accuracy after mini-batch 10800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10900: 1.885\n",
      "Train, Test accuracy after mini-batch 10900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11000: 1.887\n",
      "Train, Test accuracy after mini-batch 11000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11100: 1.886\n",
      "Train, Test accuracy after mini-batch 11100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11200: 1.884\n",
      "Train, Test accuracy after mini-batch 11200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11300: 1.886\n",
      "Train, Test accuracy after mini-batch 11300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11400: 1.885\n",
      "Train, Test accuracy after mini-batch 11400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11500: 1.885\n",
      "Train, Test accuracy after mini-batch 11500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11600: 1.886\n",
      "Train, Test accuracy after mini-batch 11600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11700: 1.886\n",
      "Train, Test accuracy after mini-batch 11700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11800: 1.885\n",
      "Train, Test accuracy after mini-batch 11800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11900: 1.886\n",
      "Train, Test accuracy after mini-batch 11900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12000: 1.888\n",
      "Train, Test accuracy after mini-batch 12000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12100: 1.886\n",
      "Train, Test accuracy after mini-batch 12100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12200: 1.886\n",
      "Train, Test accuracy after mini-batch 12200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12300: 1.887\n",
      "Train, Test accuracy after mini-batch 12300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12400: 1.885\n",
      "Train, Test accuracy after mini-batch 12400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12500: 1.886\n",
      "Train, Test accuracy after mini-batch 12500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12600: 1.886\n",
      "Train, Test accuracy after mini-batch 12600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12700: 1.886\n",
      "Train, Test accuracy after mini-batch 12700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12800: 1.886\n",
      "Train, Test accuracy after mini-batch 12800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12900: 1.887\n",
      "Train, Test accuracy after mini-batch 12900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13000: 1.887\n",
      "Train, Test accuracy after mini-batch 13000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13100: 1.887\n",
      "Train, Test accuracy after mini-batch 13100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13200: 1.887\n",
      "Train, Test accuracy after mini-batch 13200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13300: 1.886\n",
      "Train, Test accuracy after mini-batch 13300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13400: 1.885\n",
      "Train, Test accuracy after mini-batch 13400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13500: 1.886\n",
      "Train, Test accuracy after mini-batch 13500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13600: 1.885\n",
      "Train, Test accuracy after mini-batch 13600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13700: 1.887\n",
      "Train, Test accuracy after mini-batch 13700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13800: 1.886\n",
      "Train, Test accuracy after mini-batch 13800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13900: 1.885\n",
      "Train, Test accuracy after mini-batch 13900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 14000: 1.885\n",
      "Train, Test accuracy after mini-batch 14000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 14100: 1.886\n",
      "Train, Test accuracy after mini-batch 14100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 14200: 1.886\n",
      "Train, Test accuracy after mini-batch 14200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 14300: 1.887\n",
      "Train, Test accuracy after mini-batch 14300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 14400: 1.886\n",
      "Train, Test accuracy after mini-batch 14400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 14500: 1.887\n",
      "Train, Test accuracy after mini-batch 14500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after epoch     2: 1.883\n",
      "Starting epoch 3\n",
      "Loss after mini-batch   100: 1.885\n",
      "Train, Test accuracy after mini-batch 100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   200: 1.885\n",
      "Train, Test accuracy after mini-batch 200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   300: 1.886\n",
      "Train, Test accuracy after mini-batch 300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   400: 1.886\n",
      "Train, Test accuracy after mini-batch 400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   500: 1.886\n",
      "Train, Test accuracy after mini-batch 500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   600: 1.887\n",
      "Train, Test accuracy after mini-batch 600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   700: 1.886\n",
      "Train, Test accuracy after mini-batch 700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   800: 1.885\n",
      "Train, Test accuracy after mini-batch 800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   900: 1.887\n",
      "Train, Test accuracy after mini-batch 900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1000: 1.886\n",
      "Train, Test accuracy after mini-batch 1000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1100: 1.886\n",
      "Train, Test accuracy after mini-batch 1100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1200: 1.887\n",
      "Train, Test accuracy after mini-batch 1200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1300: 1.887\n",
      "Train, Test accuracy after mini-batch 1300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1400: 1.885\n",
      "Train, Test accuracy after mini-batch 1400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1500: 1.886\n",
      "Train, Test accuracy after mini-batch 1500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1600: 1.888\n",
      "Train, Test accuracy after mini-batch 1600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1700: 1.885\n",
      "Train, Test accuracy after mini-batch 1700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1800: 1.886\n",
      "Train, Test accuracy after mini-batch 1800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1900: 1.886\n",
      "Train, Test accuracy after mini-batch 1900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2000: 1.885\n",
      "Train, Test accuracy after mini-batch 2000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2100: 1.886\n",
      "Train, Test accuracy after mini-batch 2100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2200: 1.887\n",
      "Train, Test accuracy after mini-batch 2200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2300: 1.886\n",
      "Train, Test accuracy after mini-batch 2300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2400: 1.888\n",
      "Train, Test accuracy after mini-batch 2400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2500: 1.886\n",
      "Train, Test accuracy after mini-batch 2500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2600: 1.886\n",
      "Train, Test accuracy after mini-batch 2600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2700: 1.885\n",
      "Train, Test accuracy after mini-batch 2700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2800: 1.886\n",
      "Train, Test accuracy after mini-batch 2800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2900: 1.886\n",
      "Train, Test accuracy after mini-batch 2900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3000: 1.888\n",
      "Train, Test accuracy after mini-batch 3000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3100: 1.887\n",
      "Train, Test accuracy after mini-batch 3100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3200: 1.886\n",
      "Train, Test accuracy after mini-batch 3200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3300: 1.887\n",
      "Train, Test accuracy after mini-batch 3300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3400: 1.886\n",
      "Train, Test accuracy after mini-batch 3400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3500: 1.886\n",
      "Train, Test accuracy after mini-batch 3500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3600: 1.887\n",
      "Train, Test accuracy after mini-batch 3600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3700: 1.887\n",
      "Train, Test accuracy after mini-batch 3700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3800: 1.886\n",
      "Train, Test accuracy after mini-batch 3800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3900: 1.886\n",
      "Train, Test accuracy after mini-batch 3900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4000: 1.886\n",
      "Train, Test accuracy after mini-batch 4000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4100: 1.886\n",
      "Train, Test accuracy after mini-batch 4100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4200: 1.888\n",
      "Train, Test accuracy after mini-batch 4200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4300: 1.886\n",
      "Train, Test accuracy after mini-batch 4300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4400: 1.886\n",
      "Train, Test accuracy after mini-batch 4400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4500: 1.887\n",
      "Train, Test accuracy after mini-batch 4500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4600: 1.887\n",
      "Train, Test accuracy after mini-batch 4600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4700: 1.886\n",
      "Train, Test accuracy after mini-batch 4700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4800: 1.886\n",
      "Train, Test accuracy after mini-batch 4800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4900: 1.887\n",
      "Train, Test accuracy after mini-batch 4900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5000: 1.886\n",
      "Train, Test accuracy after mini-batch 5000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5100: 1.888\n",
      "Train, Test accuracy after mini-batch 5100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5200: 1.886\n",
      "Train, Test accuracy after mini-batch 5200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5300: 1.888\n",
      "Train, Test accuracy after mini-batch 5300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5400: 1.885\n",
      "Train, Test accuracy after mini-batch 5400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5500: 1.887\n",
      "Train, Test accuracy after mini-batch 5500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5600: 1.886\n",
      "Train, Test accuracy after mini-batch 5600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5700: 1.886\n",
      "Train, Test accuracy after mini-batch 5700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5800: 1.887\n",
      "Train, Test accuracy after mini-batch 5800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5900: 1.886\n",
      "Train, Test accuracy after mini-batch 5900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6000: 1.888\n",
      "Train, Test accuracy after mini-batch 6000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6100: 1.887\n",
      "Train, Test accuracy after mini-batch 6100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6200: 1.885\n",
      "Train, Test accuracy after mini-batch 6200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6300: 1.888\n",
      "Train, Test accuracy after mini-batch 6300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6400: 1.886\n",
      "Train, Test accuracy after mini-batch 6400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6500: 1.887\n",
      "Train, Test accuracy after mini-batch 6500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6600: 1.885\n",
      "Train, Test accuracy after mini-batch 6600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6700: 1.886\n",
      "Train, Test accuracy after mini-batch 6700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6800: 1.885\n",
      "Train, Test accuracy after mini-batch 6800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6900: 1.885\n",
      "Train, Test accuracy after mini-batch 6900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7000: 1.886\n",
      "Train, Test accuracy after mini-batch 7000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7100: 1.886\n",
      "Train, Test accuracy after mini-batch 7100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7200: 1.887\n",
      "Train, Test accuracy after mini-batch 7200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7300: 1.886\n",
      "Train, Test accuracy after mini-batch 7300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7400: 1.886\n",
      "Train, Test accuracy after mini-batch 7400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7500: 1.886\n",
      "Train, Test accuracy after mini-batch 7500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7600: 1.887\n",
      "Train, Test accuracy after mini-batch 7600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7700: 1.885\n",
      "Train, Test accuracy after mini-batch 7700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7800: 1.887\n",
      "Train, Test accuracy after mini-batch 7800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7900: 1.887\n",
      "Train, Test accuracy after mini-batch 7900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8000: 1.886\n",
      "Train, Test accuracy after mini-batch 8000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8100: 1.886\n",
      "Train, Test accuracy after mini-batch 8100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8200: 1.885\n",
      "Train, Test accuracy after mini-batch 8200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8300: 1.886\n",
      "Train, Test accuracy after mini-batch 8300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8400: 1.885\n",
      "Train, Test accuracy after mini-batch 8400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8500: 1.886\n",
      "Train, Test accuracy after mini-batch 8500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8600: 1.887\n",
      "Train, Test accuracy after mini-batch 8600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8700: 1.884\n",
      "Train, Test accuracy after mini-batch 8700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8800: 1.887\n",
      "Train, Test accuracy after mini-batch 8800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  8900: 1.886\n",
      "Train, Test accuracy after mini-batch 8900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9000: 1.886\n",
      "Train, Test accuracy after mini-batch 9000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9100: 1.885\n",
      "Train, Test accuracy after mini-batch 9100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9200: 1.885\n",
      "Train, Test accuracy after mini-batch 9200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9300: 1.886\n",
      "Train, Test accuracy after mini-batch 9300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9400: 1.887\n",
      "Train, Test accuracy after mini-batch 9400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9500: 1.887\n",
      "Train, Test accuracy after mini-batch 9500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9600: 1.887\n",
      "Train, Test accuracy after mini-batch 9600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9700: 1.885\n",
      "Train, Test accuracy after mini-batch 9700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9800: 1.886\n",
      "Train, Test accuracy after mini-batch 9800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  9900: 1.887\n",
      "Train, Test accuracy after mini-batch 9900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10000: 1.886\n",
      "Train, Test accuracy after mini-batch 10000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10100: 1.887\n",
      "Train, Test accuracy after mini-batch 10100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10200: 1.886\n",
      "Train, Test accuracy after mini-batch 10200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10300: 1.888\n",
      "Train, Test accuracy after mini-batch 10300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10400: 1.885\n",
      "Train, Test accuracy after mini-batch 10400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10500: 1.885\n",
      "Train, Test accuracy after mini-batch 10500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10600: 1.886\n",
      "Train, Test accuracy after mini-batch 10600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10700: 1.885\n",
      "Train, Test accuracy after mini-batch 10700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10800: 1.887\n",
      "Train, Test accuracy after mini-batch 10800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 10900: 1.886\n",
      "Train, Test accuracy after mini-batch 10900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11000: 1.885\n",
      "Train, Test accuracy after mini-batch 11000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11100: 1.886\n",
      "Train, Test accuracy after mini-batch 11100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11200: 1.886\n",
      "Train, Test accuracy after mini-batch 11200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11300: 1.886\n",
      "Train, Test accuracy after mini-batch 11300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11400: 1.887\n",
      "Train, Test accuracy after mini-batch 11400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11500: 1.887\n",
      "Train, Test accuracy after mini-batch 11500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11600: 1.886\n",
      "Train, Test accuracy after mini-batch 11600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11700: 1.887\n",
      "Train, Test accuracy after mini-batch 11700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11800: 1.886\n",
      "Train, Test accuracy after mini-batch 11800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 11900: 1.886\n",
      "Train, Test accuracy after mini-batch 11900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12000: 1.886\n",
      "Train, Test accuracy after mini-batch 12000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12100: 1.886\n",
      "Train, Test accuracy after mini-batch 12100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12200: 1.885\n",
      "Train, Test accuracy after mini-batch 12200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12300: 1.886\n",
      "Train, Test accuracy after mini-batch 12300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12400: 1.886\n",
      "Train, Test accuracy after mini-batch 12400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12500: 1.886\n",
      "Train, Test accuracy after mini-batch 12500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12600: 1.885\n",
      "Train, Test accuracy after mini-batch 12600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12700: 1.887\n",
      "Train, Test accuracy after mini-batch 12700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12800: 1.887\n",
      "Train, Test accuracy after mini-batch 12800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 12900: 1.886\n",
      "Train, Test accuracy after mini-batch 12900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13000: 1.887\n",
      "Train, Test accuracy after mini-batch 13000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13100: 1.887\n",
      "Train, Test accuracy after mini-batch 13100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13200: 1.886\n",
      "Train, Test accuracy after mini-batch 13200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13300: 1.887\n",
      "Train, Test accuracy after mini-batch 13300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13400: 1.887\n",
      "Train, Test accuracy after mini-batch 13400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13500: 1.886\n",
      "Train, Test accuracy after mini-batch 13500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13600: 1.886\n",
      "Train, Test accuracy after mini-batch 13600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13700: 1.884\n",
      "Train, Test accuracy after mini-batch 13700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13800: 1.886\n",
      "Train, Test accuracy after mini-batch 13800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 13900: 1.886\n",
      "Train, Test accuracy after mini-batch 13900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 14000: 1.887\n",
      "Train, Test accuracy after mini-batch 14000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 14100: 1.887\n",
      "Train, Test accuracy after mini-batch 14100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 14200: 1.886\n",
      "Train, Test accuracy after mini-batch 14200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 14300: 1.886\n",
      "Train, Test accuracy after mini-batch 14300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 14400: 1.886\n",
      "Train, Test accuracy after mini-batch 14400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch 14500: 1.886\n",
      "Train, Test accuracy after mini-batch 14500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after epoch     3: 1.868\n",
      "Starting epoch 4\n",
      "Loss after mini-batch   100: 1.886\n",
      "Train, Test accuracy after mini-batch 100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   200: 1.887\n",
      "Train, Test accuracy after mini-batch 200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   300: 1.886\n",
      "Train, Test accuracy after mini-batch 300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   400: 1.886\n",
      "Train, Test accuracy after mini-batch 400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   500: 1.887\n",
      "Train, Test accuracy after mini-batch 500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   600: 1.887\n",
      "Train, Test accuracy after mini-batch 600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   700: 1.886\n",
      "Train, Test accuracy after mini-batch 700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   800: 1.886\n",
      "Train, Test accuracy after mini-batch 800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch   900: 1.887\n",
      "Train, Test accuracy after mini-batch 900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1000: 1.886\n",
      "Train, Test accuracy after mini-batch 1000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1100: 1.886\n",
      "Train, Test accuracy after mini-batch 1100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1200: 1.886\n",
      "Train, Test accuracy after mini-batch 1200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1300: 1.886\n",
      "Train, Test accuracy after mini-batch 1300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1400: 1.887\n",
      "Train, Test accuracy after mini-batch 1400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1500: 1.885\n",
      "Train, Test accuracy after mini-batch 1500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1600: 1.885\n",
      "Train, Test accuracy after mini-batch 1600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1700: 1.885\n",
      "Train, Test accuracy after mini-batch 1700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1800: 1.886\n",
      "Train, Test accuracy after mini-batch 1800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  1900: 1.888\n",
      "Train, Test accuracy after mini-batch 1900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2000: 1.887\n",
      "Train, Test accuracy after mini-batch 2000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2100: 1.886\n",
      "Train, Test accuracy after mini-batch 2100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2200: 1.886\n",
      "Train, Test accuracy after mini-batch 2200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2300: 1.887\n",
      "Train, Test accuracy after mini-batch 2300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2400: 1.885\n",
      "Train, Test accuracy after mini-batch 2400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2500: 1.888\n",
      "Train, Test accuracy after mini-batch 2500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2600: 1.886\n",
      "Train, Test accuracy after mini-batch 2600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2700: 1.887\n",
      "Train, Test accuracy after mini-batch 2700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2800: 1.887\n",
      "Train, Test accuracy after mini-batch 2800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  2900: 1.887\n",
      "Train, Test accuracy after mini-batch 2900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3000: 1.887\n",
      "Train, Test accuracy after mini-batch 3000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3100: 1.887\n",
      "Train, Test accuracy after mini-batch 3100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3200: 1.887\n",
      "Train, Test accuracy after mini-batch 3200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3300: 1.886\n",
      "Train, Test accuracy after mini-batch 3300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3400: 1.886\n",
      "Train, Test accuracy after mini-batch 3400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3500: 1.886\n",
      "Train, Test accuracy after mini-batch 3500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3600: 1.886\n",
      "Train, Test accuracy after mini-batch 3600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3700: 1.886\n",
      "Train, Test accuracy after mini-batch 3700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3800: 1.888\n",
      "Train, Test accuracy after mini-batch 3800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  3900: 1.887\n",
      "Train, Test accuracy after mini-batch 3900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4000: 1.886\n",
      "Train, Test accuracy after mini-batch 4000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4100: 1.886\n",
      "Train, Test accuracy after mini-batch 4100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4200: 1.887\n",
      "Train, Test accuracy after mini-batch 4200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4300: 1.886\n",
      "Train, Test accuracy after mini-batch 4300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4400: 1.886\n",
      "Train, Test accuracy after mini-batch 4400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4500: 1.887\n",
      "Train, Test accuracy after mini-batch 4500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4600: 1.886\n",
      "Train, Test accuracy after mini-batch 4600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4700: 1.887\n",
      "Train, Test accuracy after mini-batch 4700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4800: 1.887\n",
      "Train, Test accuracy after mini-batch 4800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  4900: 1.886\n",
      "Train, Test accuracy after mini-batch 4900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5000: 1.886\n",
      "Train, Test accuracy after mini-batch 5000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5100: 1.886\n",
      "Train, Test accuracy after mini-batch 5100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5200: 1.886\n",
      "Train, Test accuracy after mini-batch 5200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5300: 1.885\n",
      "Train, Test accuracy after mini-batch 5300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5400: 1.885\n",
      "Train, Test accuracy after mini-batch 5400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5500: 1.885\n",
      "Train, Test accuracy after mini-batch 5500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5600: 1.886\n",
      "Train, Test accuracy after mini-batch 5600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5700: 1.888\n",
      "Train, Test accuracy after mini-batch 5700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5800: 1.887\n",
      "Train, Test accuracy after mini-batch 5800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  5900: 1.886\n",
      "Train, Test accuracy after mini-batch 5900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6000: 1.886\n",
      "Train, Test accuracy after mini-batch 6000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6100: 1.884\n",
      "Train, Test accuracy after mini-batch 6100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6200: 1.888\n",
      "Train, Test accuracy after mini-batch 6200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6300: 1.887\n",
      "Train, Test accuracy after mini-batch 6300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6400: 1.887\n",
      "Train, Test accuracy after mini-batch 6400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6500: 1.887\n",
      "Train, Test accuracy after mini-batch 6500: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6600: 1.886\n",
      "Train, Test accuracy after mini-batch 6600: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6700: 1.887\n",
      "Train, Test accuracy after mini-batch 6700: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6800: 1.887\n",
      "Train, Test accuracy after mini-batch 6800: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  6900: 1.886\n",
      "Train, Test accuracy after mini-batch 6900: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7000: 1.887\n",
      "Train, Test accuracy after mini-batch 7000: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7100: 1.885\n",
      "Train, Test accuracy after mini-batch 7100: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7200: 1.887\n",
      "Train, Test accuracy after mini-batch 7200: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7300: 1.887\n",
      "Train, Test accuracy after mini-batch 7300: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7400: 1.887\n",
      "Train, Test accuracy after mini-batch 7400: 0.36422917800644994, 0.36622978752700014\n",
      "Loss after mini-batch  7500: 1.886\n",
      "Train, Test accuracy after mini-batch 7500: 0.36422917800644994, 0.36622978752700014\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m current_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[39m# Iterate over the DataLoader for training data\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trainloader):\n\u001b[0;32m     26\u001b[0m     \u001b[39m# Get inputs\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     inputs, targets \u001b[39m=\u001b[39m data\n\u001b[0;32m     29\u001b[0m     \u001b[39m# Zero the gradients\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\thele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\thele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\thele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\thele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[28], line 17\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     14\u001b[0m y \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[39m# Convert the variables to tensors\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(x, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32)\n\u001b[0;32m     18\u001b[0m y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(y, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64)\n\u001b[0;32m     21\u001b[0m \u001b[39mreturn\u001b[39;00m x, y\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "mlp = nn.Sequential(OrderedDict([\n",
    "    ('input1', nn.Linear(54, 100)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('output', nn.Linear(100, 7)),\n",
    "    ('output_act', nn.Sigmoid()),\n",
    "    ('softmax', nn.Softmax(dim=1)),\n",
    "]))\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(mlp.parameters(), lr=5e-3)\n",
    "\n",
    "writer = SummaryWriter('runs/classification_mlp')\n",
    "\n",
    "\n",
    "# Run the training loop\n",
    "for epoch in range(0, 5):\n",
    "    # Print epoch\n",
    "    print(f\"Starting epoch {epoch+1}\")\n",
    "\n",
    "    # Set current loss value\n",
    "    current_loss = 0.0\n",
    "\n",
    "    # Iterate over the DataLoader for training data\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = mlp(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "\n",
    "        #Loss and accuracy for tensorboard\n",
    "        if i % 100 == 99:\n",
    "            writer.add_scalar('Loss', current_loss / 100, epoch * len(trainloader) + i)\n",
    "            print(\"Loss after mini-batch %5d: %.3f\" % (i + 1, current_loss / 100))\n",
    "            current_loss = 0.0\n",
    "            \n",
    "            y_pred_train_mlp = mlp(torch.tensor(X_train.values, dtype=torch.float32)).detach().numpy()\n",
    "\n",
    "            mlp_train_accuracy = accuracy_score(y_train, y_pred_train_mlp.argmax(axis=1) + 1)\n",
    "            \n",
    "            y_pred_test_mlp = mlp(torch.tensor(X_test.values, dtype=torch.float32)).detach().numpy()\n",
    "\n",
    "            mlp_test_accuracy = accuracy_score(y_test, y_pred_test_mlp.argmax(axis=1) + 1)\n",
    "            \n",
    "            print(f\"Train, Test accuracy after mini-batch {i+1}: {mlp_train_accuracy}, {mlp_test_accuracy}\")\n",
    "            \n",
    "            writer.add_scalar('Accuracy', {'train':mlp_train_accuracy, 'test':mlp_test_accuracy}, epoch * len(trainloader) + i)\n",
    "\n",
    "    print(\"Loss after epoch %5d: %.3f\" % (epoch + 1, loss.item()))\n",
    "    \n",
    "# Process is complete.\n",
    "print(\"Training process has finished.\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41863111689156235"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_mlp = mlp(torch.tensor(X_test.values, dtype=torch.float32)).detach().numpy()\n",
    "\n",
    "mlp_accuracy = accuracy_score(y_test, y_pred_mlp.argmax(axis=1) + 1)\n",
    "mlp_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
